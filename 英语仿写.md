# 1 Introduction
It means the system tends to only optimize the text summary generation process, while the image quality is ignored during training.
------------------------------------------------------------
It means this paper tends to only explain how to do back-propagation,while other details are omitted during writing.
# 2 review
Zhu et al. (2018) propose a multimodal attention model, in which the news with images is considered as input and a multimodal summary is gained as output.
------------------------------------------------------------
We propose a new method to predict people’s personality,in which the photo and text is considered as input and the big-five score is gained as output. 
# 3 methodology
Due to the lack of multimodal reference, the existing multimodal summarization systems are trained by the target of text modality (Eq.1), which will lead to the modality-bias problem. 
------------------------------------------------------------
Due to the lack of the graph dataset,the existing model that we design are trained by photo and text as input features,which will lead to flaw of our predict.
# 4 result and discussion
Three graduate students are asked to compare the generated multimodal summary with the reference, and assess each summary from the perspective: How informative the multimodal summary is?
------------------------------------------------------------
250 students are asked to classify the dataset and score each data from the perspective:How much is the degree of everyone’s happiness?
# 5 conclusion
In this paper, we focus on improving multimodal summarization by proposing a multimodal objective function which considers both the negative log-likelihood loss of the text summary generation and the cross-entropy loss of the image selection. 
------------------------------------------------------------
In this work,we focus on improving the interpretability of GNN by using GNN-Explainer which considers both the structure of graph and the attribute of every node in graph.
